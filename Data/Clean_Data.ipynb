{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling for NHANES Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we will clean data which was collected from the NHANES website: www.cdc.gov/nchs/nhanes/index.htm. This is the first step towards creating a predictive model for hypertension and diabetes. Aside from typical cleaning tasks carried out in data wrangling, there are special considerations due to the nature of the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in cells skipped by design in the survey\n",
    "\n",
    "The NHANES survey methods indicate occasionally skipping questions based on previous answers. For example, if the answer to the question 'Have you smoked 100 cigarettes in your lifetime?' is no, then the following question 'Are you currently smoking?' is skipped. In such columns we expect large numbers of missing values and they are easily filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating refused / don't know as missing\n",
    "\n",
    "The NHANES survey taker records responses of the SP 'refused(to answer)' and 'don't know'. Such answers are coded as numbers which are documented on the NHANES website. There are not enough of these values overall to treat them as a separate category, so we will treat them as we treat the other missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"raw_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we begin cleaning we drop SPs below age 20 \n",
    "df = df[df.RIDAGEYR >= 20]\n",
    "# Change floating points near zero to zero:\n",
    "df = df.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (34770, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DMDHREDU</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>INDHHIN2</th>\n",
       "      <th>ALQ150</th>\n",
       "      <th>BPQ020</th>\n",
       "      <th>BPQ080</th>\n",
       "      <th>DID040</th>\n",
       "      <th>DIQ010</th>\n",
       "      <th>...</th>\n",
       "      <th>BMXBMI</th>\n",
       "      <th>BMXWAIST</th>\n",
       "      <th>BMXLEG</th>\n",
       "      <th>BMXARMC</th>\n",
       "      <th>BMXARML</th>\n",
       "      <th>PHAFSTHR</th>\n",
       "      <th>LBXGLU</th>\n",
       "      <th>OHQ845</th>\n",
       "      <th>ALQ151</th>\n",
       "      <th>DMDHREDZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEQN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41475.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41477.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41479.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41481.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41482.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DMDHREDU  RIDRETH1  RIAGENDR  RIDAGEYR  INDHHIN2  ALQ150  BPQ020  \\\n",
       "SEQN                                                                        \n",
       "41475.0       4.0       5.0       2.0      62.0       6.0     2.0     1.0   \n",
       "41477.0       3.0       3.0       1.0      71.0       5.0     2.0     1.0   \n",
       "41479.0       1.0       1.0       1.0      52.0       8.0     2.0     2.0   \n",
       "41481.0       4.0       4.0       1.0      21.0       6.0     2.0     2.0   \n",
       "41482.0       4.0       1.0       1.0      64.0      15.0     1.0     1.0   \n",
       "\n",
       "         BPQ080  DID040  DIQ010  ...  BMXBMI  BMXWAIST  BMXLEG  BMXARMC  \\\n",
       "SEQN                             ...                                      \n",
       "41475.0     2.0     NaN     2.0  ...    58.0     156.0    34.0     45.0   \n",
       "41477.0     1.0    60.0     1.0  ...    30.0     110.0    32.0     34.0   \n",
       "41479.0     NaN     NaN     2.0  ...    28.0      95.0    33.0     33.0   \n",
       "41481.0     NaN     NaN     2.0  ...    23.0      80.0    44.0     31.0   \n",
       "41482.0     2.0     NaN     2.0  ...    34.0     117.0    44.0     33.0   \n",
       "\n",
       "         BMXARML  PHAFSTHR  LBXGLU  OHQ845  ALQ151  DMDHREDZ  \n",
       "SEQN                                                          \n",
       "41475.0     38.0       7.0     NaN     NaN     NaN       NaN  \n",
       "41477.0     38.0       2.0     NaN     NaN     NaN       NaN  \n",
       "41479.0     34.0      14.0   113.0     NaN     NaN       NaN  \n",
       "41481.0     43.0      12.0     NaN     NaN     NaN       NaN  \n",
       "41482.0     40.0       1.0     NaN     NaN     NaN       NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'The size of the dataset: {df.shape}')\n",
    "# Let us view the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details about each column.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 34770 entries, 41475.0 to 102956.0\n",
      "Data columns (total 37 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DMDHREDU  28300 non-null  float64\n",
      " 1   RIDRETH1  34770 non-null  float64\n",
      " 2   RIAGENDR  34770 non-null  float64\n",
      " 3   RIDAGEYR  34770 non-null  float64\n",
      " 4   INDHHIN2  33998 non-null  float64\n",
      " 5   ALQ150    9086 non-null   float64\n",
      " 6   BPQ020    34770 non-null  float64\n",
      " 7   BPQ080    31192 non-null  float64\n",
      " 8   DID040    4624 non-null   float64\n",
      " 9   DIQ010    34770 non-null  float64\n",
      " 10  DBQ197    34770 non-null  float64\n",
      " 11  DBD900    26393 non-null  float64\n",
      " 12  DBD895    34770 non-null  float64\n",
      " 13  KIQ026    34769 non-null  float64\n",
      " 14  KIQ022    34769 non-null  float64\n",
      " 15  KIQ005    30156 non-null  float64\n",
      " 16  OHQ011    5935 non-null   float64\n",
      " 17  PAQ665    34770 non-null  float64\n",
      " 18  PAQ650    34770 non-null  float64\n",
      " 19  PAQ605    34770 non-null  float64\n",
      " 20  PAQ620    34770 non-null  float64\n",
      " 21  PAQ635    34770 non-null  float64\n",
      " 22  SMQ040    15289 non-null  float64\n",
      " 23  SMQ020    34769 non-null  float64\n",
      " 24  BPXSY1    30635 non-null  float64\n",
      " 25  BPXDI1    30635 non-null  float64\n",
      " 26  BPXPLS    32056 non-null  float64\n",
      " 27  BMXBMI    32939 non-null  float64\n",
      " 28  BMXWAIST  31385 non-null  float64\n",
      " 29  BMXLEG    31329 non-null  float64\n",
      " 30  BMXARMC   31747 non-null  float64\n",
      " 31  BMXARML   31751 non-null  float64\n",
      " 32  PHAFSTHR  32827 non-null  float64\n",
      " 33  LBXGLU    15341 non-null  float64\n",
      " 34  OHQ845    27451 non-null  float64\n",
      " 35  ALQ151    16771 non-null  float64\n",
      " 36  DMDHREDZ  5306 non-null   float64\n",
      "dtypes: float64(37)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Let us view the number of missing values in each column:  \n",
    "print('Details about each column.\\n')\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining similar columns\n",
    "\n",
    "The column pairs (DMDREDU,DMDREDZ), (ALQ150,ALQ151), and (OHQ011,OHQ845) are essentially similar questions whose wording / categorization was slightly modified over the survey cycles. We first combine these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ALQ150 and ALQ151\n",
    "df.loc[df['ALQ150'].isna(), 'ALQ150'] = df['ALQ151']\n",
    "df = df.drop(['ALQ151'],axis = 1)\n",
    "\n",
    "# Combine DMDHREDU and DMDHREDZ\n",
    "# DMDHREDU must be recoded before combination:\n",
    "df.loc[(df['DMDHREDU'] == 2),'DMDHREDU'] = 1\n",
    "df.loc[(df['DMDHREDU'] == 3) | (df['DMDHREDU'] == 4),'DMDHREDU'] = 2\n",
    "df.loc[(df['DMDHREDU'] == 5),'DMDHREDU'] = 3\n",
    "# Combination:\n",
    "df.loc[df['DMDHREDU'].isna(), 'DMDHREDU'] = df['DMDHREDZ']\n",
    "df = df.drop(['DMDHREDZ'],axis = 1)\n",
    "\n",
    "# Combine OHQ011 and OHQ845\n",
    "# OHQ011 must be recoded before combination\n",
    "df['OHQ011'] = df['OHQ011'] - 10\n",
    "# Combination:\n",
    "df.loc[df['OHQ011'].isna(), 'OHQ011'] = df['OHQ845']\n",
    "df = df.drop(['OHQ845'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing dependent columns\n",
    "\n",
    "Again, we note some columns are missing a significant number of values. Most of these are due to the survey methodology of skipping certain questions based on previous answers, we will fill in these values first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values per column after filling in skipped questions and dropping rows missing blood pressure.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DMDHREDU      922\n",
       "RIDRETH1        0\n",
       "RIAGENDR        0\n",
       "RIDAGEYR        0\n",
       "INDHHIN2      546\n",
       "ALQ150       6372\n",
       "BPQ020          0\n",
       "BPQ080       3180\n",
       "DID040          3\n",
       "DIQ010          0\n",
       "DBQ197          0\n",
       "DBD900         23\n",
       "DBD895          0\n",
       "KIQ026          1\n",
       "KIQ022          1\n",
       "KIQ005       2429\n",
       "OHQ011       1244\n",
       "PAQ665          0\n",
       "PAQ650          0\n",
       "PAQ605          0\n",
       "PAQ620          0\n",
       "PAQ635          0\n",
       "SMQ040          1\n",
       "SMQ020          1\n",
       "BPXSY1          0\n",
       "BPXDI1          0\n",
       "BPXPLS          2\n",
       "BMXBMI        340\n",
       "BMXWAIST     1415\n",
       "BMXLEG       1470\n",
       "BMXARMC      1102\n",
       "BMXARML      1097\n",
       "PHAFSTHR      473\n",
       "LBXGLU      16526\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# If SP has not been told they have diabetes, then no age value.\n",
    "# First we will simplify the diabetes column\n",
    "# DIQ010 (refused / don't know/ missing) --> No\n",
    "df.loc[(df['DIQ010'] == 7) | (df['DIQ010'] == 9),'DIQ010'] = np.nan\n",
    "df.loc[df.DIQ010.isna(),'DIQ010'] = 2 \n",
    "# Simplify diabetes age column\n",
    "# replace < 1 yr w 1 and (refused / don't know) --> median\n",
    "df.loc[(df['DID040'] == 666),'DID040'] = 1  \n",
    "df.loc[(df['DID040'] == 777) | (df['DID040'] == 999) ,'DID040'] = df['DID040'].median() \n",
    "# Code <= 40 or > 40\n",
    "df.loc[(df['DID040'] <= 40),'DID040'] = 1 \n",
    "df.loc[(df['DID040'] > 40),'DID040'] = 3  \n",
    "# For those told they have borderline case add new code \n",
    "df.loc[(df['DIQ010'] == 3),'DID040'] = 2  \n",
    "# For those not told they have diabetes, add new code\n",
    "df.loc[(df['DIQ010'] == 2),'DID040'] = 0   \n",
    "\n",
    "# For the Fast food we will fill in 0 if no meals were eaten out\n",
    "df.loc[(df['DBD895'] < .5),'DBD900'] = 0    \n",
    "\n",
    "# If SP has not smoked 100 cigarettes, then not currently smoking\n",
    "df.loc[(df['SMQ020'] > 1),'SMQ040'] = 3    \n",
    "\n",
    "# We need the target values: the blood preasure measurements, so we drop those rows missing these values\n",
    "df = df.dropna(subset = ['BPXSY1','BPXDI1'])\n",
    "\n",
    "# Now let us view missing values again\n",
    "print('Number of missing values per column after filling in skipped questions and dropping rows missing blood pressure.')\n",
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there are still a large number of missing values for LBXGLU, this is blood sugar which will be used to define our target variable of being (pre)diabetic, we will drop the rows containing missing values only when we specialize to the predictive diabetes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the number of rows missing k values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      9152\n",
       "1     13233\n",
       "2      4877\n",
       "3      1819\n",
       "4       481\n",
       "5       335\n",
       "6       287\n",
       "7       282\n",
       "8       121\n",
       "9        40\n",
       "10        7\n",
       "11        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the number of missing values per row we find the majority have 2 or fewer\n",
    "print('View the number of rows missing k values:')\n",
    "df.isna().sum(axis=1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding / Cleaning\n",
    "\n",
    "We now run through each survey cleaning and recoding the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics\n",
    "\n",
    "The demographics survey includes the following features\n",
    "  * Age\n",
    "  * Gender\n",
    "  * Ethnicity\n",
    "  * Education\n",
    "  * Household Income\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will clean each survey one at a time, beginning with the Demographics survey.\n",
    "\n",
    "# Demographics\n",
    "# RIDAGEYR age  \n",
    "# RIAGENDR gender OK\n",
    "# RIDRETH1 ethnicity OK\n",
    " \n",
    "\n",
    "df = df.rename(columns={'RIAGENDR':'Gender','RIDAGEYR':'Age','RIDRETH1':'Ethnicity'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education and Income\n",
    "\n",
    "Note above there are missing values in the education DMDREDU and Income INDHHIN2 columns. We will fill in the missing education values with the mode. The missing income values will be filled with the mean income of the their eduacation level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education\n",
    "\n",
    "# Fill in Don't know/ Refused/ Missing --> Mode \n",
    "df.loc[ (df['DMDHREDU'] == 7) | (df['DMDHREDU'] == 9), 'DMDHREDU'] = np.nan\n",
    "df.loc[df['DMDHREDU'].isna(), 'DMDHREDU'] = df['DMDHREDU'].mode()[0]\n",
    "\n",
    "# Household Income \n",
    "# Under 20K\n",
    "df.loc[  df['INDHHIN2'].isin([1,2,3,4,12]), 'INDHHIN2'] = 1\n",
    "# 20K to 45K\n",
    "df.loc[  df['INDHHIN2'].isin([5,6,7]), 'INDHHIN2'] = 2\n",
    "# 45K to 75K\n",
    "df.loc[  df['INDHHIN2'].isin([8,9,10]), 'INDHHIN2'] = 3\n",
    "# Over 75K\n",
    "df.loc[  df['INDHHIN2'].isin([14,15]), 'INDHHIN2'] = 4\n",
    "# Fill in Don't know/ Refused/ Over 20K/  Missing --> mode per education group\n",
    "df.loc[  df['INDHHIN2'].isin([13,77,99]), 'INDHHIN2'] = np.nan\n",
    "\n",
    "# Impute most common income per education level:\n",
    "edu_inc = df.groupby(by=[\"DMDHREDU\"])[\"INDHHIN2\"].agg(pd.Series.mode).to_dict()\n",
    "def edu_inc_impute(a,b):\n",
    "    if np.isnan(b):\n",
    "        return edu_inc[a]\n",
    "    else:\n",
    "        return b\n",
    "df.loc[df['INDHHIN2'].isna(),'INDHHIN2'] = df.apply(lambda x: edu_inc_impute(x.DMDHREDU,x.INDHHIN2) ,axis = 1)\n",
    "\n",
    "# Rename columns\n",
    "\n",
    "df = df.rename(columns={'INDHHIN2':'HHIncome','DMDHREDU':'Education'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alcohol\n",
    "\n",
    "Ever have 4/5 or more drinks every day?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alcohol\n",
    "df.loc[ (df['ALQ150'] == 7) | (df['ALQ150'] == 9), 'ALQ150'] = np.nan\n",
    "df.loc[df['ALQ150'].isna(), 'ALQ150'] = 2\n",
    "\n",
    "df = df.rename(columns={'ALQ150':'Alcohol'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertension / Cholesterol\n",
    "\n",
    "Have you been told by your doctor you have hypertension / high cholesterol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blood Pressure & Cholesterol\n",
    "\n",
    "# Told you have Hypertension -- refused / don't know / missing --> No \n",
    "df.loc[ (df['BPQ020'] == 7) | (df['BPQ020'] == 9), 'BPQ020'] = np.nan\n",
    "df.loc[df['BPQ020'].isna(), 'BPQ020'] = 2\n",
    "    \n",
    "# Told High Cholestorol -- refused / don't know / missing --> No \n",
    "df.loc[ (df['BPQ080'] == 7) | (df['BPQ080'] == 9), 'BPQ080'] = np.nan\n",
    "df.loc[df['BPQ080'].isna(), 'BPQ080'] = 2 \n",
    "\n",
    "df = df.rename(columns={'BPQ020':'HT_YN','BPQ080':'CHOL_YN'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes\n",
    "\n",
    "The diabetes column has already been partially cleaned above, here we simply fill in missing values and drop the redundant column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes\n",
    "\n",
    "# Fill in missing value in DID040 with code 0 -- not told have diabetes\n",
    "df.loc[df.DID040.isna(), 'DID040'] = 0  \n",
    "# DIQ010 is now redundant, we drop this column \n",
    "df = df.drop(['DIQ010'],axis = 1)\n",
    "\n",
    "df = df.rename(columns={'DID040':'Diabetes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diet Behavior & Nutrition\n",
    "\n",
    "# Past 30 days milk consumption.\n",
    "# 'DBQ197' Milk consumption\n",
    "# Default = Sometimes\n",
    "df.loc[(df.DBQ197 > 3), 'DBQ197'] = 2 \n",
    "df.loc[(df.DBQ197.isna()), 'DBQ197'] = 2  \n",
    "\n",
    "# How many meals out of the home?\n",
    "# DBD895 > 21 meals -> 22 meals\n",
    "df.loc[(df.DBD895 == 5555), 'DBD895'] = 22\n",
    "# replace (refused / don't know/ missing ) --> median value\n",
    "df.loc[(df.DBD895 == 7777) | (df.DBD895 == 9999), 'DBD895'] = np.nan\n",
    "df.loc[df.DBD895.isna(), 'DBD895'] = df.DBD895.median()\n",
    "\n",
    "# How many fast food meals?\n",
    "# DBD900 \n",
    "df.loc[(df.DBD895 == 0), 'DBD900'] = 0 \n",
    "# DBD900 > 22 meals -> 22 meals\n",
    "df.loc[(df.DBD900 == 5555), 'DBD900'] = 22  \n",
    "# replace (refused / don't know / missing) --> median value\n",
    "df.loc[(df.DBD900 == 7777) | (df.DBD900 == 9999), 'DBD900'] = np.nan\n",
    "df.loc[df.DBD900.isna(), 'DBD900'] = df.DBD900.median() \n",
    "\n",
    "df = df.rename(columns={'DBQ197':'Milk','DBD895':'MealsOut','DBD900':'FastFood'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Kidney questionaire\n",
    "    \n",
    "# Told Weak kidney (refused / don't know/ missing) --> No\n",
    "df.loc[(df.KIQ022 == 7) | (df.KIQ022 == 9),'KIQ022'] = np.nan\n",
    "df.loc[df.KIQ022.isna(),'KIQ022'] = 2 \n",
    "    \n",
    "# Kidney stones (refused / don't know/ missing) --> No\n",
    "df.loc[(df.KIQ026 == 7) | (df.KIQ026 == 9),'KIQ026'] = np.nan\n",
    "df.loc[df.KIQ026.isna(), 'KIQ026'] = 2  \n",
    "    \n",
    "# Urinary leakage (refused / don't know/ missing --> Never\n",
    "df.loc[(df.KIQ005 == 7) | (df.KIQ005 == 9),'KIQ005'] = np.nan\n",
    "df.loc[df.KIQ005.isna(),'KIQ005'] = 1\n",
    "\n",
    "df = df.rename(columns={'KIQ022':'WeakKidneys','KIQ026':'KidneyStones','KIQ005':'UrineLeak'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dental Health\n",
    "\n",
    "Rate the overall health of your teeth and gums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dental health (refused / don't know/ missing) --> good\n",
    "df.loc[df.OHQ011 > 5,'OHQ011'] = np.nan\n",
    "df.loc[df.OHQ011.isna(),'OHQ011'] = 3\n",
    "\n",
    "df = df.rename(columns = {'OHQ011':'Dental'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physical Activity\n",
    "\n",
    "Does your job involve moderate/vigorous work activity?\n",
    "Do you walk or bike to work?\n",
    "Do you participate in moderate/vigorous recreational activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical Activity questionaire\n",
    "    \n",
    "# Vig work  (refused / don't know/ missing) --> No\n",
    "df.loc[(df.PAQ605 == 7) | (df.PAQ605 == 9),'PAQ605'] = np.nan\n",
    "df.loc[df.PAQ605.isna(),'PAQ605'] = 2    \n",
    "    \n",
    "# Moderate work  (refused / don't know/ missing) --> No\n",
    "df.loc[(df.PAQ620 == 7) | (df.PAQ620 == 9),'PAQ620'] = np.nan\n",
    "df.loc[df.PAQ620.isna(),'PAQ620'] = 2  \n",
    "    \n",
    "# Combine moderate and vigorous work\n",
    "df['Work_Act'] = df[['PAQ605','PAQ620']].min(axis=1)\n",
    "#df = df.drop(['PAQ605','PAQ620'],axis = 1)\n",
    "\n",
    "# Walk / Bike\n",
    "# (refused / don't know / missing) --> No\n",
    "df.loc[(df.PAQ635 == 7) | (df.PAQ635 == 9),'PAQ635'] = np.nan\n",
    "df.loc[df.PAQ635.isna(),'PAQ635'] = 2     \n",
    "        \n",
    "# Vig rec (refused / don't know/ missing) --> No\n",
    "df.loc[(df.PAQ650 == 7) | (df.PAQ650 == 9),'PAQ650'] = np.nan\n",
    "df.loc[df.PAQ650.isna(),'PAQ650'] = 2     \n",
    "    \n",
    "# Moderate rec  (refused / don't know/ missing) --> No\n",
    "df.loc[(df.PAQ665 == 7) | (df.PAQ665 == 9),'PAQ665'] = np.nan\n",
    "df.loc[df.PAQ665.isna(),'PAQ665'] = 2    \n",
    "    \n",
    "# Combine moderate and vigorous rec \n",
    "df['Rec_Act'] = df[['PAQ650','PAQ665']].min(axis=1)\n",
    "#df = df.drop(['PAQ650','PAQ665'],axis = 1)\n",
    "\n",
    "df = df.rename(columns={'PAQ635':'WalkBike','PAQ605':'Vig_Work','PAQ620':'Mod_Work','PAQ650':'Vig_Rec','PAQ665':'Mod_Rec'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Smoking\n",
    "    \n",
    "# Smoking 100 (refused / don't know/ missing) --> No\n",
    "df.loc[(df.SMQ020 == 7) | (df.SMQ020 == 9),'SMQ020'] = np.nan\n",
    "df.loc[df.SMQ020.isna(),'SMQ020'] = 2   \n",
    "    \n",
    "# Smoking 100 = No >> Currently Smoking = No\n",
    "df.loc[(df.SMQ020 == 2),'SMQ040'] = 3 \n",
    "    \n",
    "# Currently Smoking (refused / don't know/ missing) --> No\n",
    "df.loc[(df.SMQ040 == 7) | (df.SMQ040 == 9),'SMQ040'] = np.nan\n",
    "df.loc[df.SMQ040.isna(),'SMQ040'] = 3   \n",
    "    \n",
    "\n",
    "df = df.rename(columns={'SMQ020':'Smoke_100','SMQ040':'Smoke_now'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body Measurements\n",
    "\n",
    "Measurements include:\n",
    " * BMI\n",
    " * Waist\n",
    " * Leg Length\n",
    " * Arm Length\n",
    " * Arm Circumference\n",
    " \n",
    "Missing values will be replaced by the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body measurement\n",
    "\n",
    "# BMXBMI BMI measurement\n",
    "# replace missing with median\n",
    "df.loc[(df.BMXBMI.isna()),'BMXBMI'] = df.BMXBMI.median()\n",
    "df.loc[(df.BMXWAIST.isna()),'BMXWAIST'] = df.BMXWAIST.median()\n",
    "df.loc[(df.BMXLEG.isna()),'BMXLEG'] = df.BMXLEG.median()\n",
    "df.loc[(df.BMXARML.isna()),'BMXARML'] = df.BMXARML.median()\n",
    "df.loc[(df.BMXARMC.isna()),'BMXARMC'] = df.BMXARMC.median()\n",
    "\n",
    "df = df.rename(columns={'BMXBMI':'BMI','BMXWAIST':'WAIST','BMXLEG':'LegLen','BMXARML':'ArmLen','BMXARMC':'ArmCirc'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circulatory Measurements\n",
    "\n",
    "Measurements include:\n",
    " * Pulse\n",
    " * Systolic pressure\n",
    " * Diastolic pressure\n",
    "\n",
    "Missing pulse values will be replaced with the median. \n",
    "\n",
    "Systolic and Diastolic pressure will be used to construct the target variable: Diagnosis of Hypertension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Pulse\n",
    "df.loc[(df.BPXPLS.isna()),'BPXPLS'] = df.BPXPLS.median()\n",
    "\n",
    "# Let us add a new feature encoding Non-elevated, Elevated, and High blood preasure\n",
    "df['HT_Diag'] = -1\n",
    "df.loc[(df.BPXSY1 < 120) & (df.BPXDI1 < 80),'HT_Diag'] = 0 \n",
    "df.loc[(df.BPXSY1 >= 120) & (df.BPXDI1 < 80),'HT_Diag'] = 1 \n",
    "df.loc[(df.BPXSY1 >= 130) | (df.BPXDI1 >= 80),'HT_Diag'] = 2  \n",
    "\n",
    "df = df.rename(columns={'BPXPLS':'Pulse'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    13408\n",
       "0    12176\n",
       "1     5051\n",
       "Name: HT_Diag, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.HT_Diag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the Systolic and Diastolic measurements\n",
    "# df = df.drop(columns = ['BPXSY1','BPXDI1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education           0\n",
       "Ethnicity           0\n",
       "Gender              0\n",
       "Age                 0\n",
       "HHIncome            0\n",
       "Alcohol             0\n",
       "HT_YN               0\n",
       "CHOL_YN             0\n",
       "Diabetes            0\n",
       "Milk                0\n",
       "FastFood            0\n",
       "MealsOut            0\n",
       "KidneyStones        0\n",
       "WeakKidneys         0\n",
       "UrineLeak           0\n",
       "Dental              0\n",
       "Mod_Rec             0\n",
       "Vig_Rec             0\n",
       "Vig_Work            0\n",
       "Mod_Work            0\n",
       "WalkBike            0\n",
       "Smoke_now           0\n",
       "Smoke_100           0\n",
       "BPXSY1              0\n",
       "BPXDI1              0\n",
       "Pulse               0\n",
       "BMI                 0\n",
       "WAIST               0\n",
       "LegLen              0\n",
       "ArmCirc             0\n",
       "ArmLen              0\n",
       "PHAFSTHR          473\n",
       "LBXGLU          16526\n",
       "Work_Act            0\n",
       "Rec_Act             0\n",
       "HT_Diag             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check missing values\n",
    "\n",
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"clean_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30635, 36)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
